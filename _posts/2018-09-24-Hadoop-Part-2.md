---
layout: post
title: Hadoop - Taming The Elephant, Part 1
tags: hadoop big-data tutorial
---

## Introduction

This part of the tutorial series, will show you, how to...

* ... put data into HDFS
* ... write a MapReduce job in Java
* ... run the job on the imported data
* ... read data from HDFS
* ... remove data from HDFS

## What is MapReduce?

## Prerequisites

If you want to use this tutorial as a hands-on, you'll need:

* Running Docker-container from part 1 of the series
* Dataset from Kaggle.com (For downloading it, you'll need an account)
* JDK and a Java-IDE of your choice
* Maven

## Get your dataset into HDFS

### Get it in

### Did it work?

## Write MapReduce job in Java

### Prerequisites

* MapReduce dependency
* jar-bundler

### The Mapper

### The Reducer

### Start-up

## Run the job

### Get it into the container

### Run it

### See the results

### Remove the results

## What's part 3 going to be about?